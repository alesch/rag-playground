## Evaluation Metrics

### Retrieval Quality

- **Precision@K**: Relevant docs in top K results
- **Recall@K**: % of relevant docs retrieved
- **MRR**: Mean Reciprocal Rank of first relevant result

### Generation Quality

- **Accuracy**: Factually correct answers
- **Completeness**: All aspects of question addressed
- **Citation Quality**: Proper source attribution
- **Readability**: Well-formatted markdown

### Manual Evaluation

Create evaluation set:
- 20-30 sample questions
- Ground truth answers
- Expected sources
