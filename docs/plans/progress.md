# TDD Progress Tracker

**Last Updated**: 2026-01-06
**Current Status**: Phase 4 Generation IN PROGRESS ğŸ”„

---

## Completed Components

### Component 1: Document Loader âœ…
**Status**: All tests passing (5/5)

Completed tests:
1. âœ… Load single markdown file and extract frontmatter fields (version, title, tags)
2. âœ… Generate document_id by slugifying title
3. âœ… Load all corpus documents
4. âœ… Raise error when required frontmatter fields are missing (version or title)

---

### Component 2: Chunker âœ…
**Status**: All tests passing (12/12)

Completed tests:
1. âœ… Split document by markdown headers preserving context
2. âœ… Respect maximum chunk size limit
3. âœ… Apply overlap between consecutive chunks (verified no wasteful overlap at natural boundaries)
4. âœ… Generate unique chunk IDs and preserve revision in metadata
5. â­ï¸ Handle minimum chunk size constraint (skipped - not needed with LangChain)

---

### Component 3: Embedder âœ…
**Status**: All tests passing (4/4)

Completed tests:
1. âœ… Generate 1024-dimensional embedding for text via Ollama
2. âœ… Batch embed multiple texts maintaining order
3. âœ… Raise error when Ollama service unavailable
4. âœ… Validate and reject empty input text

---

### Component 4: Supabase Client âœ…
**Module**: `src/database/supabase_client.py`
**Test File**: `tests/test_supabase_client.py`
**Status**: All tests passing (7/7)

Completed tests:
1. âœ… Initialize connection with credentials
2. âœ… Insert chunk with content, embedding, revision, and status
3. âœ… Batch insert multiple chunks efficiently
4. âœ… Enforce UNIQUE constraint on (document_id, chunk_id, revision)
5. âœ… Allow different revisions of same chunk_id
6. âœ… Mark previous revisions as superseded when inserting new revision
7. âœ… Query and filter chunks by status

**Key Implementation Details**:
- SupabaseClient class with credential validation
- Connection verification via `is_connected()` method
- ChunkKey dataclass for composite key (document_id, chunk_id, revision)
- ChunkRecord dataclass using composition (contains ChunkKey + data)
- `insert_chunk()` method accepts ChunkRecord, auto-supersedes previous active revisions
- `batch_insert_chunks()` method for efficient bulk inserts
- `delete_chunk()` method accepts ChunkKey for test cleanup
- `get_chunk_revisions()` returns `Dict[int, ChunkRecord]`
- `query_chunks_by_status()` returns `List[ChunkRecord]` filtered by status
- `_row_to_chunk_record()` helper to reconstruct ChunkRecord from DB row
- `_prepare_chunk_data()` helper method to reduce duplication
- Pytest module-scoped client fixture
- Table name extracted from config (CHUNKS_TABLE)
- JSON parsing for embedding vectors returned as strings from Supabase

---

### Component 5: Full Pipeline Integration âœ…
**Module**: `scripts/ingest_corpus.py`
**Test File**: `tests/test_ingestion_pipeline.py`
**Status**: All tests passing (4/4)

Completed tests:
1. âœ… Ingest single document end-to-end
2. âœ… Ingest full corpus (4 documents)
3. âœ… Re-ingestion supersedes previous revisions
4. âœ… Ingestion returns statistics (per-document results)

**Key Implementation Details**:
- `IngestionResult` dataclass for single document results
- `CorpusIngestionResult` dataclass for corpus results
- `ingest_document()` loads, chunks, embeds, and stores a single document
- `ingest_corpus()` processes all documents in a directory
- `_process_document()` helper eliminates duplication
- `_build_chunk_records()` helper for ChunkRecord construction
- Batch operations: `generate_embeddings()` + `batch_insert_chunks()`
- `batch_insert_chunks()` auto-supersedes previous active revisions
- Renamed `batch_embed` to `generate_embeddings` for clarity

**Test Performance Optimizations**:
- `MockSupabaseClient` in conftest.py for in-memory database testing
- `mock_embeddings` fixture returns deterministic fake embeddings
- `mock_database` fixture patches SupabaseClient in ingest_corpus module
- Integration tests run in ~0.5s instead of ~116s (230x speedup)
- Supabase client tests still hit real database for full validation

---

### Component 6: Retriever âœ…
**Module**: `src/retrieval/retriever.py`
**Test File**: `tests/test_retriever.py`
**Status**: 3 tests passing, 2 skipped

Completed tests:
1. âœ… Search returns similar chunks
2. â­ï¸ Results ordered by similarity (skipped - guaranteed by pgvector SQL)
3. âœ… Respects top_k limit
4. âœ… Only returns active chunks
5. â­ï¸ Respects similarity threshold (skipped - guaranteed by pgvector SQL)

**Key Implementation Details**:
- `Retriever` class wraps embedding generation and database search
- `SearchResult` dataclass in `supabase_client.py` (shared interface)
- `search_by_embedding()` method uses PostgreSQL RPC for pgvector search
- `search_chunks` PostgreSQL function for vector similarity
- Tests use `MockSupabaseClient` for fast execution

---

### Component 7: Generator ğŸ”„
**Module**: `src/generation/generator.py`
**Test File**: `tests/test_generator.py`
**Status**: In progress (3/4 tests passing)

Completed tests:
1. âœ… Generate answer from retrieved chunks
2. âœ… Answer includes citations to source chunks
3. âœ… Handle empty retrieval results gracefully (skip LLM call, save tokens)

Remaining tests:
4. â³ Prompt includes all retrieved context

---
