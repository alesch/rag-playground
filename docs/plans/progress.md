# TDD Progress Tracker

**Last Updated**: 2026-01-30
**Current Status**: Phase 6 Component 3 COMPLETED

---

## Phase 5.6: Persistence Layer âœ…

### Component 1: Schema & Initialization âœ…

**Status**: All tests passing (7/7 in test_sqlite_client.py)

- âœ… Define SQL schema for domain tables (native SQLite)
- âœ… Update `SQLiteClient` to initialize domain tables
- âœ… Enable foreign key support

### Component 2: QuestionnaireStore (SQL) âœ…

**Status**: All tests passing (5/5 in test_questionnaire_store.py)

- âœ… Refactor store to use `SQLiteClient`
- âœ… Implement SQL CRUD operations

### Component 3: RunStore (SQL) âœ…

**Module**: `src/domain/run_store.py`
**Test File**: `tests/test_run_store.py` & `tests/test_run_config.py`
**Status**: All tests passing (8/8)

- âœ… Refactor store to use `SQLiteClient`
- âœ… Implement SQL CRUD operations
- âœ… Handle JSON serialization for complex fields (retrieved chunks)
- âœ… Implement immutable `RunConfig` separation and reusability

### Component 4: Citation Normalization âœ…

**Status**: All tests passing (2/2 in test_citation_normalization.py)

- âœ… Create `citations` table
- âœ… Refactor `RunStore` to use relational citations instead of JSON
- âœ… Verify cascade deletion

### Component 5: Retrieved Chunks Normalization âœ…

**Status**: All tests passing (2/2 in test_chunks_normalization.py)

- âœ… Create `retrieved_chunks` table
- âœ… Refactor `RunStore` to use relational chunks helper methods
- âœ… Verify cascade deletion
- âœ… Remove redundant JSON columns

---

## Phase 6: Refinement & Optimization ðŸš§

### Component 1: Evaluation Pipeline âœ…

**Status**: Completed (Metrics, Ground Truth, and Evaluation CLI implemented)

- âœ… Implement metrics
  - âœ… Precision@K
  - âœ… Recall@K
  - âœ… MRR
  - âœ… Answer Relevancy (Semantic similarity)
- âœ… Establish and import Ground Truth (NotebookLM output with section/order preservation)
- âœ… Automate evaluation runner logic (`RAGEvaluator`)
- âœ… Create evaluation CLI tool (`run_evaluation.py`)

### Component 2: Orchestration Refinement

**Status**: Pending

- [ ] Integrate LangGraph state management (if needed)
- [ ] Implement conditional routing (e.g., "Not Found" -> Retry/Web Search)

### Component 3: Performance Tuning ðŸš§

**Status**: In Progress - ExperimentRunner ready, architecture refactored

**Experiments Phase:**
- [x] Create short test questionnaire (3 questions for rapid iteration)
- [x] Establish baseline metrics (Mean Relevancy: 0.8085)
- [x] Run 13 systematic experiments on retrieval and LLM parameters
- [x] Find optimal configuration (temp=0.3, threshold=0.3, top_k=5)
- [x] Achieve +10.7% quality improvement + 28% speed improvement
- [x] Update config.py with optimized defaults for llama3.2
- [x] Create validation scripts (TDD tested)
- [x] Validate on full 50-question: baseline BEATS optimized (-1.47%)
- [x] Plan revised experiment strategy (7 configs Ã— 3 trials)

**Architecture Refactoring:**
- [x] Rename Generator â†’ RAGSystem (better reflects purpose)
- [x] Add configuration parameters to RAGSystem (temperature, top_k, threshold)
- [x] ExperimentRunner uses RAGSystem directly (not Orchestrator)
- [x] RunConfig parameters now applied to RAG system
- [x] Mark Orchestrator for future LangGraph work
- [x] Create code reorganization plan (deferred until after experiments)
- [x] RAGSystem refactored to accept Question objects (uses section metadata)
- [x] QuestionnaireRunner bypasses Orchestrator, uses RAGSystem directly
- [x] All callers verified to use Question objects appropriately

**ExperimentRunner TDD (5/5 tests passing - READY FOR EXPERIMENTS):**
- [x] Test 1: Happy path - returns run_id, questions_answered, success
- [x] Test 2: RAG system called and answers saved to DB
- [x] Test 3: Evaluation performed and metrics returned
- [x] Test 4: Retry logic - fails 2x then succeeds on 3rd attempt
- [x] Test 5: Batch processing - 2 configs Ã— 2 trials = 4 experiments
- [x] Refactored: Removed monkeypatching, use dependency injection with RAGSystem

**Experiment Script Ready:**
- [x] Created scripts/tuning.py (configurable for any questionnaire)
- [x] Supports --questionnaire and --trials arguments
- [x] Tests 7 configurations (baseline, 2 temp, 2 threshold, 2 top-k)
- [x] Refactored for readability (extracted helper functions)

**Next Steps:**
- [ ] Test with 3-question questionnaire (quick validation)
- [ ] Run overnight experiment suite (7 configs Ã— 3 trials = 21 experiments, ~8 hours)
- [ ] Analyze results and update config with validated parameters
- [ ] Document final validated findings
- [ ] Code reorganization (minimal: group rag/, move stores/)

---

## Phase 7: Infrastructure & Deployment ðŸš§

### Component 1: DigitalOcean Setup âœ…

**Status**: doctl authenticated, Python-slim Dockerfile created.

- âœ… Install and authenticate `doctl`
- âœ… Create `Dockerfile` (Python-slim) and `.dockerignore`
- âœ… Create `scripts/entrypoint.sh` for automatic Ollama startup
- âœ… Create DigitalOcean Container Registry (`alesch-registry`)
- âœ… Build lean Docker image (301 MB)
- âœ… Push image to DOCR
- âœ… Setup persistent Volume for models (20GB in NYC3)
- âœ… Create initial setup Droplet
- âœ… Download models to Volume (DeepSeek, Llama3, Gemma, etc.)
- âœ… Create data directory and upload initial DB
- [ ] Create automation scripts
